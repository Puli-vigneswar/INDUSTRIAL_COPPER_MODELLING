{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,r2_score,mean_squared_error,classification_report,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV ,train_test_split\n",
    "df=pd.read_csv(\"D:/copperman/copperman.csv\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"quantity tons\":\"tons_quantity\",\n",
    "                   \"item type\":\"item_type\",\n",
    "                   \"delivery date\":\"delivery_date\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"country\"]==df[\"country\"].fillna(0,inplace=True)\n",
    "df[\"country\"]=df[\"country\"].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"item_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tons_quantity\"]=pd.to_numeric(df[\"tons_quantity\"],errors='coerce')\n",
    "df[\"customer\"]=pd.to_numeric(df[\"customer\"],errors='coerce')\n",
    "df[\"country\"]=pd.to_numeric(df[\"country\"],errors='coerce')\n",
    "df[\"application\"]=pd.to_numeric(df['application'],errors='coerce')\n",
    "df[\"thickness\"]=pd.to_numeric(df['thickness'],errors='coerce')\n",
    "df[\"width\"]=pd.to_numeric(df['width'],errors='coerce')\n",
    "df[\"item_date\"]=pd.to_datetime(df['item_date'],format='%Y%m%d',errors='coerce').dt.date\n",
    "df[\"delivery_date\"]=pd.to_datetime(df['delivery_date'],format='%Y%m%d',errors='coerce').dt.date\n",
    "df[\"product_ref\"]=pd.to_numeric(df['product_ref'],errors='coerce')\n",
    "df[\"material_ref\"]=df[\"material_ref\"].str.lstrip('0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "print(missing_values_count)\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['material_ref'].fillna('unknown', inplace=True)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = df.isnull().sum()\n",
    "print(null_count)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tons_quantity\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['thickness'])\n",
    "plt.show()\n",
    "sns.distplot(df['width'])\n",
    "plt.show()\n",
    "sns.distplot(df['selling_price'])\n",
    "plt.show()\n",
    "sns.distplot(df['tons_quantity'])\n",
    "plt.show()\n",
    "sns.distplot(df['country'])\n",
    "plt.show()\n",
    "sns.distplot(df['application'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "negsell= df['selling_price'] <= 0\n",
    "print(negsell.sum())\n",
    "df.loc[negsell, 'selling_price'] = np.nan\n",
    "\n",
    "negtons = df['tons_quantity'] <= 0\n",
    "print(negtons.sum())\n",
    "df.loc[negtons, 'tons_quantity'] = np.nan\n",
    "\n",
    "negth = df['thickness'] <= 0\n",
    "print(negth.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "df.dropna(inplace=True)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tons_quantity'] = df['tons_quantity'].apply(lambda x: np.nan if x <= 0 else x)\n",
    "# Apply log transformation\n",
    "df['tons_quantity_log'] = np.log(df['tons_quantity'])\n",
    "sns.distplot(df['tons_quantity_log'].dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thickness_log'] = np.log(df['thickness'])\n",
    "sns.distplot(df['thickness_log'].dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selling_price_log'] = np.log(df['selling_price'])  \n",
    "# Using np.log to handle zero values\n",
    "sns.distplot(df['selling_price_log'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['tons_quantity_log',\n",
    "      'application',\n",
    "      'thickness_log',\n",
    "      'width','selling_price_log',\n",
    "      'country',\n",
    "      'customer',\n",
    "      'product_ref']].corr()\n",
    "sns.heatmap(x, annot=True,cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(subset=['selling_price_log'])\n",
    "\n",
    "# Separate categorical values (X) and target variable (y)\n",
    "X = df_cleaned.drop('selling_price_log', axis=1)\n",
    "y = df_cleaned['selling_price_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical variables\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(X[['item_type']])\n",
    "X_ohe = ohe.fit_transform(X[['item_type']]).toarray()\n",
    "ohe2 = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe2.fit(X[['status']])\n",
    "X_be = ohe2.fit_transform(X[['status']]).toarray()\n",
    "# independent features after encoding\n",
    "X = np.concatenate((X[['tons_quantity_log',\n",
    "                       'application',\n",
    "                       'thickness_log',\n",
    "                       'width','country',\n",
    "                       'customer',\n",
    "                       'product_ref']].values,\n",
    "                    X_ohe, X_be), axis=1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# test and train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decision tree regression\n",
    "dtr = DecisionTreeRegressor()\n",
    "# hyperparameters\n",
    "param_grid = {'max_depth': [3, 5, 9, 17],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearchcv\n",
    "grid_search = GridSearchCV(estimator=dtr, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalution metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Mean squared error:', mse)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"item_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"width\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([[np.log(40),99 , np.log(2),\n",
    "                        5, 28,30202938,\n",
    "                        1670798778,'PL','']])\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_sample_ohe = ohe.transform(sample[:, [7]]).toarray()\n",
    "new_sample_be = ohe2.transform(sample[:, [8]]).toarray()\n",
    "new_sample = np.concatenate((sample[:, [0,1,2, 3, 4, 5, 6]],\n",
    "                             new_sample_ohe,new_sample_be), axis=1)\n",
    "sc_sample1 = scaler.transform(new_sample)\n",
    "new_pred = best_model.predict(sc_sample1)\n",
    "print('Predicted selling price:', np.exp(new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to pickle the decision tree model,standard scaler,one hot encoders,\n",
    "'''\n",
    "with open('decisiontreemodel.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "with open('standardscaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('onehotencoder.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe, f)\n",
    "with open('onehotencoder2.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe2, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_cleaned))\n",
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df_cleaned[df_cleaned['status'].isin(['Won', 'Lost'])]\n",
    "len(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_4.to_csv(\"D:/copperman/dataframe_coppermodel.csv\",index=False)\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dfc['status']\n",
    "X= dfc[['tons_quantity_log','selling_price_log',\n",
    "         'item_type','application','thickness_log',\n",
    "         'width','country','customer','product_ref']]\n",
    "# encoding categorical variables\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(X[['item_type']])\n",
    "X_ohe = ohe.fit_transform(X[['item_type']]).toarray()\n",
    "be = LabelBinarizer()\n",
    "be.fit(Y) \n",
    "y = be.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical values after encoding\n",
    "X = np.concatenate((X[['tons_quantity_log', 'selling_price_log','application',\n",
    "                       'thickness_log', 'width','country',\n",
    "                       'customer','product_ref']].values, X_ohe), axis=1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=18)\n",
    "# decision tree classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.5])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the status for a new sample\n",
    "# 'quantity tons_log', 'selling_price_log','application', 'thickness_log', 'width','country','customer','product_ref'\n",
    "new_sample = np.array([[np.log(700), np.log(956), 10, np.log(2),1500,28.0,30202938,1670798778,'W']])\n",
    "new_sample_ohe = ohe.transform(new_sample[:, [8]]).toarray()\n",
    "new_sample = np.concatenate((new_sample[:, [0,1,2, 3, 4, 5, 6,7]], new_sample_ohe), axis=1)\n",
    "new_sample = scaler.transform(new_sample)\n",
    "new_pred = dtc.predict(new_sample)\n",
    "if new_pred==1:\n",
    "    print('The status is: Won')\n",
    "else:\n",
    "    print('The status is: Lost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Saving the model\n",
    "import pickle\n",
    "with open('classificationmodel.pkl', 'wb') as file:\n",
    "    pickle.dump(dtc, file)\n",
    "with open('classificationscaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('classification_encoder_t.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
